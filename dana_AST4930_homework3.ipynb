{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AST 4930 Homework Assignment #3 (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All work is due Tuesday September 26 at 5 pm.\n",
    "\n",
    "## Instruction: \n",
    "Do all homework in this Jupyter notebook and submit your final .ipynb file via Canvas. Show ALL your work and try to add comment lines as needed to describe what your code does. \n",
    "\n",
    "You are encouraged to discuss homework problems with your classmates. However, your python script and answers to the questions must be written by yourself.\n",
    "\n",
    "It's fine if you use someone else's code you found on Internet, but make sure you write down the source. You don't have to cite me when you use anything from AST4930 Notebook.\n",
    "\n",
    "It's a common sense but just to make sure, when you make a figure make sure they are readable/understandable. If you cannot see the title, labels, data points, or if you don't understand the point of the figure, I won't probably be able to see/understand them either.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Curse of dimensionality (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned that kNN suffers from the curse of dimensionality. In class, we estimated the size of a hypercube that includes $k$ nearest neighbors as a function of dimension and number of data points. In this homework, let's look into this problem in a more quantitative way by following the steps below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Make six $D$-dimensional numpy arrays, where we adopt $D = 1, 2, 5, 10, 100,$ and $1000$, each of which contains $n=10^4$ data points that are randomly distributed in the $D$-dimensional space (hint: use np.random.rand). Let's assume that the side of each hypercube ranges from 0 to 1, so the volume of hypercubes is 1. (1 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "n = 10000\n",
    "arr1d = np.random.rand(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96799954],\n",
       "       [0.08978459],\n",
       "       [0.62349933],\n",
       "       ...,\n",
       "       [0.22297724],\n",
       "       [0.93443333],\n",
       "       [0.50406387]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d = np.random.rand(n,2)\n",
    "arr5d = np.random.rand(n,5)\n",
    "arr10d = np.random.rand(n,10)\n",
    "arr100d = np.random.rand(n,100)\n",
    "arr1000d = np.random.rand(n,1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) For each array, compute the distance between each data points. Since you have $10^4$ data points in each array, you need to compute distance total $(10,000 \\times 9,999)/2 = 49,995,000$ times. You could use a for loop, but it will be very slow. Instead, I found ``distance_matrix`` from ``scipy.spatial`` does a decent job. Once you computed all the distance, normalize them by the maximum possible distance in each hypercube, that is $\\sqrt{D}$. (1 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "#dimensions = (1,2,5,10,100,1000)\n",
    "\n",
    "\n",
    "dist1 = distance_matrix(arr1d, arr1d)\n",
    "dist1 = dist1 /np.sqrt(1)\n",
    "\n",
    "dist2 = distance_matrix(arr2d, arr2d)\n",
    "dist2 = dist2 /np.sqrt(2)\n",
    "\n",
    "dist5 = distance_matrix(arr5d, arr5d)\n",
    "dist5 = dist5 / np.sqrt(5)\n",
    "\n",
    "dist10 = distance_matrix(arr10d, arr10d)\n",
    "dist10 = dist10 /np.sqrt(10)\n",
    "\n",
    "dist100 = distance_matrix(arr100d, arr100d)\n",
    "dist100 = dist100 / np.sqrt(100)\n",
    "\n",
    "dist1000 = distance_matrix(arr1000d, arr1000d)\n",
    "dist1000 = dist1000 / np.sqrt(1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) In a single figure, plot histograms showing the number of counts on the y axis vs. normalized distance between data points on the x axis. You have six arrays, so you will have to over-plot six histograms. Label them properly so that readers can understand what the figure shows. (1 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f81371aa400>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(dist1.flatten(), color='blue', label = \"1D\")\n",
    "plt.hist(dist2.flatten(), color='red',label = \"2D\")\n",
    "plt.hist(dist5.flatten(), color='green',label = \"5D\")\n",
    "plt.hist(dist10.flatten(), color='orange',label = \"10D\")\n",
    "plt.hist(dist100.flatten(),  color='purple',label = \"100D\")\n",
    "plt.hist(dist1000.flatten(), color='brown',label = \"1000D\")\n",
    "\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(dist1.ravel(), color='blue', label = \"1D\")\n",
    "plt.hist(dist2.ravel(), color='red',label = \"2D\")\n",
    "plt.hist(dist5.ravel(), color='green',label = \"5D\")\n",
    "plt.hist(dist10.ravel(), color='orange',label = \"10D\")\n",
    "plt.hist(dist100.ravel(),  color='purple',label = \"100D\")\n",
    "plt.hist(dist1000.ravel(), color='brown',label = \"1000D\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Discuss what you see in the figure you made in the context of kNN. (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**\"As the dimensions increase, the spread of datapoints becomes wider and wider. This shows the curse of dimensionality because with more dimensions, more more computational power is required.\"**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Classifying objects in SDSS data using kNN and decision tree (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDSS.csv file contains various information on 150,000 stars, galaxies, and quasars, including ugriz magnitudes and redshift. Let's build kNN and DT models based on this dataset. You may want to use pandas to read in the data (https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Using the provided ugriz magnitudes, compute and store u-g, g-r, r-i, i-z colors for each object. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('SDSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237655107828973746</td>\n",
       "      <td>138.937318</td>\n",
       "      <td>49.779249</td>\n",
       "      <td>17.32152</td>\n",
       "      <td>16.28594</td>\n",
       "      <td>15.88471</td>\n",
       "      <td>15.66384</td>\n",
       "      <td>15.46604</td>\n",
       "      <td>2243</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>152</td>\n",
       "      <td>862475375345690624</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.028514</td>\n",
       "      <td>766</td>\n",
       "      <td>52247</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237678584114511952</td>\n",
       "      <td>31.594644</td>\n",
       "      <td>22.451246</td>\n",
       "      <td>18.13019</td>\n",
       "      <td>17.47997</td>\n",
       "      <td>16.97868</td>\n",
       "      <td>16.75768</td>\n",
       "      <td>16.83714</td>\n",
       "      <td>7709</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>2303710287351539712</td>\n",
       "      <td>QSO</td>\n",
       "      <td>1.694959</td>\n",
       "      <td>2046</td>\n",
       "      <td>53327</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237680298881122360</td>\n",
       "      <td>333.991221</td>\n",
       "      <td>19.977552</td>\n",
       "      <td>18.94798</td>\n",
       "      <td>18.80473</td>\n",
       "      <td>18.75522</td>\n",
       "      <td>18.72968</td>\n",
       "      <td>18.66552</td>\n",
       "      <td>8108</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>8532228490187264000</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.046520</td>\n",
       "      <td>7578</td>\n",
       "      <td>56956</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1237650761319514319</td>\n",
       "      <td>186.201096</td>\n",
       "      <td>-2.808180</td>\n",
       "      <td>19.22969</td>\n",
       "      <td>18.04638</td>\n",
       "      <td>17.37830</td>\n",
       "      <td>16.99285</td>\n",
       "      <td>16.76479</td>\n",
       "      <td>1231</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>113</td>\n",
       "      <td>376103378880587776</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334</td>\n",
       "      <td>51993</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237648722280317126</td>\n",
       "      <td>124.814240</td>\n",
       "      <td>0.651496</td>\n",
       "      <td>18.76061</td>\n",
       "      <td>17.28682</td>\n",
       "      <td>16.74055</td>\n",
       "      <td>16.55152</td>\n",
       "      <td>16.45902</td>\n",
       "      <td>756</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>2316149895234349056</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>2057</td>\n",
       "      <td>53816</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1237673758185554973</td>\n",
       "      <td>100.889697</td>\n",
       "      <td>29.106283</td>\n",
       "      <td>19.17071</td>\n",
       "      <td>18.21106</td>\n",
       "      <td>17.80099</td>\n",
       "      <td>17.63203</td>\n",
       "      <td>17.53079</td>\n",
       "      <td>6585</td>\n",
       "      <td>301</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "      <td>3013004977846118400</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>2676</td>\n",
       "      <td>54179</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>1237671262268752282</td>\n",
       "      <td>124.964450</td>\n",
       "      <td>9.635759</td>\n",
       "      <td>19.38253</td>\n",
       "      <td>17.49415</td>\n",
       "      <td>16.55436</td>\n",
       "      <td>16.13420</td>\n",
       "      <td>15.80408</td>\n",
       "      <td>6004</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>2728125362876737536</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.110984</td>\n",
       "      <td>2423</td>\n",
       "      <td>54149</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>1237673756573762584</td>\n",
       "      <td>98.821075</td>\n",
       "      <td>26.946457</td>\n",
       "      <td>18.90948</td>\n",
       "      <td>17.73591</td>\n",
       "      <td>17.31252</td>\n",
       "      <td>17.16612</td>\n",
       "      <td>17.07103</td>\n",
       "      <td>6585</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>3035579600630474752</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>2696</td>\n",
       "      <td>54167</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1237678877782966354</td>\n",
       "      <td>320.766012</td>\n",
       "      <td>9.993010</td>\n",
       "      <td>17.63177</td>\n",
       "      <td>16.10855</td>\n",
       "      <td>15.35884</td>\n",
       "      <td>15.21912</td>\n",
       "      <td>15.11279</td>\n",
       "      <td>7777</td>\n",
       "      <td>301</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>821986413082863616</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>730</td>\n",
       "      <td>52466</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>1237671124296204669</td>\n",
       "      <td>132.118725</td>\n",
       "      <td>10.789925</td>\n",
       "      <td>19.17574</td>\n",
       "      <td>17.70970</td>\n",
       "      <td>16.85068</td>\n",
       "      <td>16.41647</td>\n",
       "      <td>16.14956</td>\n",
       "      <td>5972</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>2898128276260153344</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.174877</td>\n",
       "      <td>2574</td>\n",
       "      <td>54084</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      objid          ra        dec         u         g  \\\n",
       "0       1237655107828973746  138.937318  49.779249  17.32152  16.28594   \n",
       "1       1237678584114511952   31.594644  22.451246  18.13019  17.47997   \n",
       "2       1237680298881122360  333.991221  19.977552  18.94798  18.80473   \n",
       "3       1237650761319514319  186.201096  -2.808180  19.22969  18.04638   \n",
       "4       1237648722280317126  124.814240   0.651496  18.76061  17.28682   \n",
       "...                     ...         ...        ...       ...       ...   \n",
       "149995  1237673758185554973  100.889697  29.106283  19.17071  18.21106   \n",
       "149996  1237671262268752282  124.964450   9.635759  19.38253  17.49415   \n",
       "149997  1237673756573762584   98.821075  26.946457  18.90948  17.73591   \n",
       "149998  1237678877782966354  320.766012   9.993010  17.63177  16.10855   \n",
       "149999  1237671124296204669  132.118725  10.789925  19.17574  17.70970   \n",
       "\n",
       "               r         i         z   run  rerun  camcol  field  \\\n",
       "0       15.88471  15.66384  15.46604  2243    301       3    152   \n",
       "1       16.97868  16.75768  16.83714  7709    301       3     65   \n",
       "2       18.75522  18.72968  18.66552  8108    301       5     79   \n",
       "3       17.37830  16.99285  16.76479  1231    301       3    113   \n",
       "4       16.74055  16.55152  16.45902   756    301       5     60   \n",
       "...          ...       ...       ...   ...    ...     ...    ...   \n",
       "149995  17.80099  17.63203  17.53079  6585    301       6    121   \n",
       "149996  16.55436  16.13420  15.80408  6004    301       5     61   \n",
       "149997  17.31252  17.16612  17.07103  6585    301       3    103   \n",
       "149998  15.35884  15.21912  15.11279  7777    301       6     66   \n",
       "149999  16.85068  16.41647  16.14956  5972    301       4    111   \n",
       "\n",
       "                  specobjid   class  redshift  plate    mjd  fiberid  \n",
       "0        862475375345690624  GALAXY  0.028514    766  52247      131  \n",
       "1       2303710287351539712     QSO  1.694959   2046  53327      433  \n",
       "2       8532228490187264000     QSO  2.046520   7578  56956      578  \n",
       "3        376103378880587776  GALAXY  0.000000    334  51993      192  \n",
       "4       2316149895234349056    STAR  0.000196   2057  53816      632  \n",
       "...                     ...     ...       ...    ...    ...      ...  \n",
       "149995  3013004977846118400    STAR  0.000160   2676  54179      352  \n",
       "149996  2728125362876737536  GALAXY  0.110984   2423  54149      254  \n",
       "149997  3035579600630474752    STAR  0.000097   2696  54167      558  \n",
       "149998   821986413082863616    STAR -0.000218    730  52466      289  \n",
       "149999  2898128276260153344  GALAXY  0.174877   2574  54084      225  \n",
       "\n",
       "[150000 rows x 18 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = data['u']\n",
    "g = data['g']\n",
    "r = data['r']\n",
    "i = data['i']\n",
    "data['ug'] = data['u'] - data['g']\n",
    "data['gr'] = data['g'] - data['r']\n",
    "data['ri'] = data['r'] - data['i']\n",
    "data['iz'] = data['i'] - data['z']\n",
    "redshift = data['redshift']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         GALAXY\n",
       "1            QSO\n",
       "2            QSO\n",
       "3         GALAXY\n",
       "4           STAR\n",
       "           ...  \n",
       "149995      STAR\n",
       "149996    GALAXY\n",
       "149997      STAR\n",
       "149998      STAR\n",
       "149999    GALAXY\n",
       "Name: class, Length: 150000, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset or replace this with your data loading code\n",
    "# X should be your feature matrix, and y should be your target labels\n",
    "# Replace the following lines with your data loading code\n",
    "X = data[['ug', 'gr', 'ri', 'iz', 'redshift', 'u', 'g', 'r', 'i']]\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize lists to store training and test accuracies\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# Vary k from 1 to 30\n",
    "k_values = range(1, 31)\n",
    "\n",
    "for k in k_values:\n",
    "    # Create a kNN classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and test data\n",
    "    y_train_pred = knn.predict(X_train)\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the training and test accuracies\n",
    "    train_accuracy.append(accuracy_score(y_train, y_train_pred))\n",
    "    test_accuracy.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Plot training and test accuracy vs. k\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_accuracy, label='Training Accuracy')\n",
    "plt.plot(k_values, test_accuracy, label='Test Accuracy')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy vs. k for k-Nearest Neighbors')\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal k that results in the highest test accuracy\n",
    "optimal_k = k_values[np.argmax(test_accuracy)]\n",
    "print(f'The optimal k for highest test accuracy is: {optimal_k}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Make a kNN model. Vary $k$ from 1 to 30 and make a figure showing training/test accuracy vs. $k$. What is the optimal $k$ that results in the highest test accuracy? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset or replace this with your data loading code\n",
    "# X should be your feature matrix, and y should be your target labels\n",
    "# Replace the following lines with your data loading code\n",
    "X = data[['ug', 'gr', 'ri', 'iz', 'redshift', 'u', 'g', 'r', 'i']]\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize lists to store training and test accuracies\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# Vary max_depth from 1 to 30\n",
    "max_depth_values = range(1, 31)\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    # Create a Decision Tree classifier with max_depth\n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth, random_state=0)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training and test data\n",
    "    y_train_pred = dt.predict(X_train)\n",
    "    y_test_pred = dt.predict(X_test)\n",
    "    \n",
    "    # Calculate and store the training and test accuracies\n",
    "    train_accuracy.append(accuracy_score(y_train, y_train_pred))\n",
    "    test_accuracy.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Plot training and test accuracy vs. max_depth\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depth_values, train_accuracy, label='Training Accuracy')\n",
    "plt.plot(max_depth_values, test_accuracy, label='Test Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy vs. Max Depth for Decision Tree')\n",
    "plt.xticks(max_depth_values)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find the optimal max_depth that results in the highest test accuracy\n",
    "optimal_max_depth = max_depth_values[np.argmax(test_accuracy)]\n",
    "print(f'The optimal max_depth for highest test accuracy is: {optimal_max_depth}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Make a DT model. Vary max_depth from 1 to 30 and make a figure showing training/test accuracy vs. max_depth. What is the optimal max_depth that results in the highest test accuracy? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest numbers more important:\n",
      "('ug', 0.4403076518773627)\n",
      "('gr', 0.008429583336188106)\n",
      "('ri', 0.008819737941081082)\n",
      "('iz', 0.007844625852335042)\n",
      "('redshift', 0.5262312865084979)\n",
      "('u', 0.0027540724601158918)\n",
      "('g', 0.0014434116401951095)\n",
      "('r', 0.002034903421730968)\n",
      "('i', 0.002134726962493095)\n",
      "redshift and u-g are most important\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['ug', 'gr', 'ri', 'iz', 'redshift', 'u', 'g', 'r', 'i']  \n",
    "feature_importances = dt.feature_importances_\n",
    "\n",
    "feature_tuples = list(zip(feature_names, feature_importances))\n",
    "\n",
    "print(\"largest numbers more important:\")\n",
    "\n",
    "for feature_tuple in feature_tuples:\n",
    "    print(feature_tuple)\n",
    "print(\"redshift and u-g are most important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) For your best decision tree model, which features are the most important? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN model w/ eval data: 0.5650866666666666\n",
      "Accuracy of DT model w/ eval data: 0.6672933333333333\n"
     ]
    }
   ],
   "source": [
    "#load new dataset\n",
    "eval_data = pd.read_csv('SDSS_evaluation.csv')\n",
    "\n",
    "#prepare features of eval data\n",
    "eval_data['ug'] = eval_data['u'] - eval_data['g']\n",
    "eval_data['gr'] = eval_data['g'] - eval_data['r']\n",
    "eval_data['ri'] = eval_data['r'] - eval_data['i']\n",
    "eval_data['iz'] = eval_data['i'] - eval_data['z']\n",
    "\n",
    "#label x and y with new eval data\n",
    "X_eval = eval_data[['ug', 'gr', 'ri', 'iz', 'redshift', 'u', 'g', 'r', 'i']]\n",
    "y_eval = eval_data['class']\n",
    "\n",
    "#best kNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_accuracy = knn_model.score(X_eval, y_eval)\n",
    "\n",
    "#best decision tree model\n",
    "DT_model = DecisionTreeClassifier(max_depth=optimal_max_depth, random_state=0)\n",
    "DT_model.fit(X_train, y_train)\n",
    "DT_accuracy = DT_model.score(X_eval, y_eval)\n",
    "\n",
    "print(\"Accuracy of kNN model w/ eval data:\", knn_accuracy)\n",
    "print(\"Accuracy of DT model w/ eval data:\", DT_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) SDSS_evaluation.csv file contains another 150,000 stars, galaxies, and quasars. Using the best kNN and decision tree models you obtained, make predictions for this new dataset and compute the accuracy. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Counts in data:\n",
      "GALAXY    50000\n",
      "QSO       50000\n",
      "STAR      50000\n",
      "Name: class, dtype: int64\n",
      "Class Counts in eval_data:\n",
      "GALAXY    86323\n",
      "STAR      33085\n",
      "QSO       30592\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass Counts in data:\")\n",
    "print(data['class'].value_counts())\n",
    "\n",
    "print(\"Class Counts in eval_data:\")\n",
    "print(eval_data['class'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) You should have gotten poor performance from your kNN and decision tree models unless you did some magic. Have a look at the your training/evaluation datasets and discuss what might have caused poor performace. (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The poor performance is probably due to poor training data, in that the training data is not representative of the evaluation data. There is an even split of each in the original data, but in the eval data there are way more galaxies than stars and QSOs.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
